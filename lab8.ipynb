{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_bwuDEUvf3H"
      },
      "outputs": [],
      "source": [
        "#A2\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import uniform\n",
        "\n",
        "def input_dataset(path):\n",
        "  dataset=pd.read_excel(path)\n",
        "  inputs = dataset.iloc[:, :-1].values  # Features: all columns except the last attribute\n",
        "  targets = dataset.iloc[:, -1].values  # Target: last column\n",
        "  return inputs, targets\n",
        "\n",
        "def divide_dataset(inputs, targets,test_size=0.2, random_state=40):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=test_size, random_state=random_state)\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "def set_hyperparameters():\n",
        "    parameter_space = {\n",
        "        'hidden_layer_sizes': [(10,), (50,), (100,), (50, 50)],  # Setting no. of neurons per hidden layer\n",
        "        'activation': ['tanh', 'relu', 'sigmoid'],\n",
        "        'alpha': uniform(0.0001, 0.05),\n",
        "        'learning_rate_init': uniform(0.001, 0.1),  # Initial learning rate\n",
        "        'learning_rate': ['constant', 'adaptive'],  # How the learning rate can be adjusted\n",
        "    }\n",
        "    return parameter_space\n",
        "\n",
        "def train_classifier_model(X_train, y_train, param_dist, n_iterations=50, cv=5): #cv is cross validation\n",
        "    \"\"\"Performs hyperparameter tuning using RandomizedSearchCV and trains the model.\"\"\"\n",
        "    mlp = MLPClassifier(max_iter=10000)\n",
        "    random_search = RandomizedSearchCV(mlp, param_distributions=param_dist, n_iterations=n_iterations, cv=cv, random_state=42, n_jobs=-1) #n_jobs: use all the available processes in your machine for parallel processing\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters found: {random_search.best_params_}\")\n",
        "    print(f\"Best cross-validation score: {random_search.best_score_}\")\n",
        "\n",
        "    return random_search.best_estimator_ #in-built function, gives the best performing model after hyper-parameter tuning\n",
        "\n",
        "def test_model(model, X_test, Y_test): #tests the model based on the test dataset to calculate accuracy\n",
        "    y_predicted = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_predicted)\n",
        "    print(f\"Test accuracy: {accuracy}\")\n",
        "\n",
        "    for i, input_data in enumerate(X_test[:15]): #printing the first 15 predictions\n",
        "        prediction = model.predict([input_data])\n",
        "        print(f\"Input: {input_data} - Predicted Output: {prediction[0]} - Expected Output: {y_test[i]}\")\n",
        "\n",
        "  path=\"/content/bird_species_features.xlsx\"\n",
        "  inputs, targets = input_dataset(path)\n",
        "  X_train, X_test, y_train, y_test = divide_dataset(inputs, targets)\n",
        "  param_dist = set_hyperparameters()\n",
        "  best_model = (X_train, y_train, param_dist)\n",
        "  test_model(best_model, X_test, y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A2\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import uniform\n",
        "\n",
        "def input_dataset(path):\n",
        "    dataset = pd.read_excel(path)\n",
        "    inputs = dataset.iloc[:, :-1].values  # Features: all columns except the last attribute\n",
        "    targets = dataset.iloc[:, -1].values  # Target: last column\n",
        "    return inputs, targets\n",
        "\n",
        "def divide_dataset(inputs, targets, test_size=0.2, random_state=40):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=test_size, random_state=random_state)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def set_hyperparameters():\n",
        "    parameter_space = {\n",
        "        'hidden_layer_sizes': [(10,), (50,), (100,), (50, 50)],  # Setting no. of neurons per hidden layer\n",
        "        'activation': ['tanh', 'relu', 'sigmoid'],\n",
        "        'alpha': uniform(0.0001, 0.05),\n",
        "        'learning_rate_init': uniform(0.001, 0.1),  # Initial learning rate\n",
        "        'learning_rate': ['constant', 'adaptive'],  # How the learning rate can be adjusted\n",
        "    }\n",
        "    return parameter_space\n",
        "\n",
        "def train_classifier_model(X_train, y_train, param_dist, n_iterations=50, cv=5):  # cv is cross validation\n",
        "    \"\"\"Performs hyperparameter tuning using RandomizedSearchCV and trains the model.\"\"\"\n",
        "    mlp = MLPClassifier(max_iter=10000)\n",
        "    random_search = RandomizedSearchCV(mlp, param_distributions=param_dist, n_iter=n_iterations, cv=cv, random_state=42, n_jobs=-1)  # n_jobs: use all the available processes in your machine for parallel processing\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters found: {random_search.best_params_}\")\n",
        "    print(f\"Best cross-validation score: {random_search.best_score_}\")\n",
        "\n",
        "    return random_search.best_estimator_  # in-built function, gives the best performing model after hyper-parameter tuning\n",
        "\n",
        "def test_model(model, X_test, y_test):  # tests the model based on the test dataset to calculate accuracy\n",
        "    y_predicted = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_predicted)\n",
        "    print(f\"Test accuracy: {accuracy}\")\n",
        "\n",
        "    for i, input_data in enumerate(X_test[:15]):  # printing the first 15 predictions\n",
        "        prediction = model.predict([input_data])\n",
        "        print(f\"Input: {input_data} - Predicted Output: {prediction[0]} - Expected Output: {y_test[i]}\")\n",
        "\n",
        "# Main script logic\n",
        "path = \"/content/bird_species_features.xlsx\"\n",
        "inputs, targets = input_dataset(path)\n",
        "X_train, X_test, y_train, y_test = divide_dataset(inputs, targets)\n",
        "param_dist = set_hyperparameters()\n",
        "best_model = train_classifier_model(X_train, y_train, param_dist)  # Call the training function\n",
        "test_model(best_model, X_test, y_test)  # Test the best model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iaq-RyemABDz",
        "outputId": "d78aa02b-6022-4556-fac6-f1d81c860dcb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "\nAll the 250 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n38 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n    estimator._validate_params()\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'identity', 'logistic', 'relu', 'tanh'}. Got 'sigmoid' instead.\n\n--------------------------------------------------------------------------------\n52 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n    estimator._validate_params()\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'identity', 'relu', 'logistic', 'tanh'}. Got 'sigmoid' instead.\n\n--------------------------------------------------------------------------------\n32 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 751, in fit\n    return self._fit(X, y, incremental=False)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 441, in _fit\n    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1096, in _validate_input\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'D:\\\\bird_songs\\\\460220.mp3'\n\n--------------------------------------------------------------------------------\n128 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 751, in fit\n    return self._fit(X, y, incremental=False)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 441, in _fit\n    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1096, in _validate_input\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'D:\\\\bird_songs\\\\357932.mp3'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-84a7a5fbb89b>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivide_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mparam_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_classifier_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dist\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Call the training function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Test the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-84a7a5fbb89b>\u001b[0m in \u001b[0;36mtrain_classifier_model\u001b[0;34m(X_train, y_train, param_dist, n_iterations, cv)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mrandom_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# n_jobs: use all the available processes in your machine for parallel processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best parameters found: {random_search.best_params_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1958\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1961\u001b[0m             ParameterSampler(\n\u001b[1;32m   1962\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    994\u001b[0m                     )\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             )\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 250 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n38 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n    estimator._validate_params()\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'identity', 'logistic', 'relu', 'tanh'}. Got 'sigmoid' instead.\n\n--------------------------------------------------------------------------------\n52 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n    estimator._validate_params()\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n    validate_parameter_constraints(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'identity', 'relu', 'logistic', 'tanh'}. Got 'sigmoid' instead.\n\n--------------------------------------------------------------------------------\n32 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 751, in fit\n    return self._fit(X, y, incremental=False)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 441, in _fit\n    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1096, in _validate_input\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'D:\\\\bird_songs\\\\460220.mp3'\n\n--------------------------------------------------------------------------------\n128 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 751, in fit\n    return self._fit(X, y, incremental=False)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 441, in _fit\n    X, y = self._validate_input(X, y, incremental, reset=first_pass)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 1096, in _validate_input\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1301, in check_X_y\n    X = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1012, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\", line 745, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\nValueError: could not convert string to float: 'D:\\\\bird_songs\\\\357932.mp3'\n"
          ]
        }
      ]
    }
  ]
}