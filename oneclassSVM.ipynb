{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "-59stCCAXWxN",
        "outputId": "77744dbc-b5c1-414e-f889-3bcfa3a213dc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pydub'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-404461d6c908>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixture\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Step 1: Read the Excel file for bird species and audio paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydub'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "from scipy.signal import butter, lfilter\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Step 1: Read the Excel file for bird species and audio paths\n",
        "def load_audio_metadata(excel_file):\n",
        "    try:\n",
        "        df = pd.read_excel(excel_file)\n",
        "        df1 = df.head(4600)  # Limit to 20 rows for now\n",
        "        audio_paths = []\n",
        "        for index, row in df1.iterrows():\n",
        "            recording_id = row['id_num']\n",
        "            file_name = os.path.join('D:\\\\bird_songs', f'{recording_id}.mp3')\n",
        "            if os.path.exists(file_name):\n",
        "                audio_paths.append(file_name)\n",
        "            else:\n",
        "                print(f\"File not found: {file_name}\")\n",
        "        species = df['en'].tolist()  # Assuming 'en' column contains species names\n",
        "        return audio_paths, species\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading metadata from {excel_file}: {e}\")\n",
        "        return [], []\n",
        "\n",
        "# Step 2: Preprocess the audio file by applying a high-pass filter to reduce background noise\n",
        "def butter_highpass_filter(data, cutoff=1000, fs=22050, order=5):\n",
        "    try:\n",
        "        nyquist = 0.5 * fs\n",
        "        normal_cutoff = cutoff / nyquist\n",
        "        b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
        "        y = lfilter(b, a, data)\n",
        "        return y\n",
        "    except Exception as e:\n",
        "        print(f\"Error applying high-pass filter: {e}\")\n",
        "        return data  # Return unfiltered data if error occurs\n",
        "\n",
        "def preprocess_audio(audio_file):\n",
        "    try:\n",
        "        audio, sr = librosa.load(audio_file, sr=None)\n",
        "        filtered_audio = butter_highpass_filter(audio, cutoff=1000, fs=sr)\n",
        "        return filtered_audio, sr\n",
        "    except Exception as e:\n",
        "        print(f\"Error preprocessing audio file {audio_file}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Step 3: Advanced Voice Activity Detection (VAD) using energy-based segmentation\n",
        "def detect_bird_calls(audio, sr, threshold=0.02):\n",
        "    try:\n",
        "        # Calculate the root mean square (RMS) energy of the audio\n",
        "        energy = librosa.feature.rms(y=audio)[0]  # 'y' specifies the audio signal\n",
        "\n",
        "        # Split the audio into segments based on silence and sound\n",
        "        segments = librosa.effects.split(audio, top_db=25)  # Splitting non-silent segments\n",
        "\n",
        "        # Filter segments based on energy threshold\n",
        "        bird_segments = [segment for segment in segments if np.mean(energy[int(segment[0] // 512):int(segment[1] // 512)]) > threshold]\n",
        "\n",
        "        return bird_segments\n",
        "    except Exception as e:\n",
        "        print(f\"Error detecting bird calls in the audio: {e}\")\n",
        "        return []\n",
        "\n",
        "# Step 4: Ensure segments are at least 1 to 2 seconds long by merging short segments\n",
        "def segment_audio(audio, sr, segments, min_duration=1.0, max_duration=2.0):\n",
        "    try:\n",
        "        min_samples = int(min_duration * sr)  # Minimum segment duration in samples\n",
        "        max_samples = int(max_duration * sr)  # Maximum segment duration in samples\n",
        "        segmented_clips = []\n",
        "        current_segment = None\n",
        "\n",
        "        for start, end in segments:\n",
        "            if current_segment is None:\n",
        "                current_segment = [start, end]\n",
        "            else:\n",
        "                # Merge segments if too short\n",
        "                if end - current_segment[0] < min_samples:\n",
        "                    current_segment[1] = end  # Extend current segment\n",
        "                else:\n",
        "                    if current_segment[1] - current_segment[0] >= min_samples:\n",
        "                        segmented_clips.append(audio[current_segment[0]:current_segment[1]])\n",
        "                    current_segment = [start, end]\n",
        "\n",
        "        # Append the last segment if it meets the minimum duration requirement\n",
        "        if current_segment and (current_segment[1] - current_segment[0] >= min_samples):\n",
        "            segmented_clips.append(audio[current_segment[0]:current_segment[1]])\n",
        "\n",
        "        return segmented_clips\n",
        "    except Exception as e:\n",
        "        print(f\"Error segmenting the audio: {e}\")\n",
        "        return []\n",
        "\n",
        "# Step 5: Visualize and analyze the detected segments\n",
        "def visualize_segments(audio, sr, segments):\n",
        "    try:\n",
        "        '''\n",
        "        plt.figure(figsize=(14, 5))\n",
        "        librosa.display.waveshow(audio, sr=sr, alpha=0.5)\n",
        "        for start, end in segments:\n",
        "            plt.axvspan(start / sr, end / sr, color='red', alpha=0.3)\n",
        "        plt.title('Detected Bird Call Segments')\n",
        "        plt.show()\n",
        "        '''\n",
        "        print(\"hi done\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error visualizing the segments: {e}\")\n",
        "\n",
        "# Step 6: Save the refined audio segments\n",
        "def save_segments(audio_segments, sr, output_dir, file_name):\n",
        "    try:\n",
        "        # Ensure the output directory exists\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        for i, segment in enumerate(audio_segments):\n",
        "            # Define the output file path\n",
        "            output_path = f\"{output_dir}\\\\{file_name}_segment_{i}.mp3\"\n",
        "\n",
        "            # Check if the segment file already exists\n",
        "            if os.path.exists(output_path):\n",
        "                print(f\"Segment {output_path} already exists. Skipping...\")\n",
        "                continue\n",
        "\n",
        "            # Convert float32 audio data to int16 format (Pydub works with int16)\n",
        "            segment_int16 = np.int16(segment * 32767)  # Convert float [-1, 1] to int16 range\n",
        "\n",
        "            # Create an AudioSegment from the numpy array\n",
        "            segment_audio = AudioSegment(\n",
        "                segment_int16.tobytes(),  # Convert to bytes\n",
        "                frame_rate=sr,            # Sampling rate\n",
        "                sample_width=2,           # 2 bytes per sample (16-bit PCM)\n",
        "                channels=1                # Assuming mono audio\n",
        "            )\n",
        "\n",
        "            # Export the segment as an MP3 file\n",
        "            print(f\"Saving segment to: {output_path}\")\n",
        "            segment_audio.export(output_path, format=\"mp3\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving audio segments: {e}\")\n",
        "\n",
        "'''\n",
        "def save_segments(audio_segments, sr, output_dir, file_name):\n",
        "    try:\n",
        "        # Ensure the output directory exists\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        for i, segment in enumerate(audio_segments):\n",
        "            # Convert float32 audio data to int16 format (Pydub works with int16)\n",
        "            segment_int16 = np.int16(segment * 32767)  # Convert float [-1, 1] to int16 range\n",
        "\n",
        "            # Create an AudioSegment from the numpy array\n",
        "            segment_audio = AudioSegment(\n",
        "                segment_int16.tobytes(),  # Convert to bytes\n",
        "                frame_rate=sr,            # Sampling rate\n",
        "                sample_width=2,           # 2 bytes per sample (16-bit PCM)\n",
        "                channels=1                # Assuming mono audio\n",
        "            )\n",
        "            # Export the segment as an MP3 file\n",
        "            output_path = f\"{output_dir}\\\\{file_name}_segment_{i}.mp3\"\n",
        "            print(f\"Saving segment to: {output_path}\")\n",
        "            segment_audio.export(output_path, format=\"mp3\")\n",
        "            print(f\"Saved segment {i} to {output_dir}/{file_name}_segment_{i}.mp3\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving audio segments: {e}\")\n",
        "'''\n",
        "\n",
        "# Main logic for processing all files\n",
        "def process_bird_audio_files(excel_file, output_dir):\n",
        "    audio_paths, species_list = load_audio_metadata(excel_file)\n",
        "\n",
        "    for i, audio_file in enumerate(audio_paths):\n",
        "        try:\n",
        "            print(f\"Processing {audio_file} for species {species_list[i]}...\")\n",
        "            preprocessed_audio, sr = preprocess_audio(audio_file)\n",
        "\n",
        "            if preprocessed_audio is None:\n",
        "                print(f\"Skipping file {audio_file} due to preprocessing failure.\")\n",
        "                continue\n",
        "\n",
        "            bird_segments = detect_bird_calls(preprocessed_audio, sr)\n",
        "            segmented_clips = segment_audio(preprocessed_audio, sr, bird_segments)\n",
        "\n",
        "            if segmented_clips:\n",
        "                visualize_segments(preprocessed_audio, sr, bird_segments)\n",
        "                save_segments(segmented_clips, sr, output_dir, os.path.basename(audio_file).split('.')[0])\n",
        "            else:\n",
        "                print(f\"No bird segments detected in {audio_file}.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file {audio_file}: {e}\")\n",
        "\n",
        "# Execution\n",
        "try:\n",
        "    excel_file_path = 'C:\\\\Users\\\\NEW\\\\Documents\\\\Python Scripts\\\\ML\\\\birds_india.xlsx'\n",
        "    output_directory = 'D:\\\\refined_bird_calls'\n",
        "    process_bird_audio_files(excel_file_path, output_directory)\n",
        "except Exception as e:\n",
        "    print(f\"Critical error during execution: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load your dataset (replace this with actual loading code)\n",
        "dataset = np.load('/content/refined_bird_species_features.xlsx')  # Load the full dataset here\n",
        "labels = np.concatenate([np.ones(100), -np.ones(100)])  # Replace with actual labels if available\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.5, stratify=labels, random_state=42)\n",
        "X_train = X_train[y_train == 1]  # Keep only bird calls for training\n",
        "\n",
        "# Initialize and train the One-Class SVM\n",
        "model = OneClassSVM(kernel=\"rbf\", gamma=\"auto\", nu=0.1)\n",
        "model.fit(X_train)\n",
        "\n",
        "# Predict and evaluate on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print the accuracy and classification report\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "WMkSQMxGf_Wb",
        "outputId": "f0e1faf5-e423-41d4-a209-5e436e3e9b90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [9, 200]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-db1b1d502997>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Split dataset into train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Keep only bird calls for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2780\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2782\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2784\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [9, 200]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example Dataset and Labels (replace this with actual data loading code)\n",
        "# Ensure dataset and labels have the same number of samples\n",
        "dataset = np.concatenate([np.random.normal(0, 1, (100, 20)), np.random.uniform(-4, 4, (100, 20))])  # Example data\n",
        "labels = np.concatenate([np.ones(100), -np.ones(100)])  # 1 for bird call, -1 for no bird call\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.5, stratify=labels, random_state=42)\n",
        "X_train = X_train[y_train == 1]  # Keep only bird calls for training\n",
        "\n",
        "# Initialize and train the One-Class SVM\n",
        "model = OneClassSVM(kernel=\"rbf\", gamma=\"auto\", nu=0.1)\n",
        "model.fit(X_train)\n",
        "\n",
        "# Predict and evaluate on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print the accuracy and classification report\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gCJpUdRh0pF",
        "outputId": "d3902a2f-dae0-4130-e091-d05578b9006d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.69\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.62      1.00      0.76        50\n",
            "         1.0       1.00      0.38      0.55        50\n",
            "\n",
            "    accuracy                           0.69       100\n",
            "   macro avg       0.81      0.69      0.66       100\n",
            "weighted avg       0.81      0.69      0.66       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset and labels as before\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.5, stratify=labels, random_state=42)\n",
        "X_train = X_train[y_train == 1]\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Model training with tuned parameters\n",
        "model = OneClassSVM(kernel=\"rbf\", gamma=0.01, nu=0.05)\n",
        "model.fit(X_train)\n",
        "\n",
        "# Prediction and evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0ZqxZr1kd4g",
        "outputId": "57402dba-ede7-4170-a1a7-212abd61f044"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.81\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.72      1.00      0.84        50\n",
            "         1.0       1.00      0.62      0.77        50\n",
            "\n",
            "    accuracy                           0.81       100\n",
            "   macro avg       0.86      0.81      0.80       100\n",
            "weighted avg       0.86      0.81      0.80       100\n",
            "\n"
          ]
        }
      ]
    }
  ]
}